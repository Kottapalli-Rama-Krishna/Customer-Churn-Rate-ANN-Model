{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "708cd640",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db65eb7e",
   "metadata": {},
   "source": [
    "Being a Data Scientist at a telecom company “Leo” whose customers are churning out to its \n",
    "competitors. We have to analyse the data of your company and find insights and stop your customers from \n",
    "churning out to other telecom companies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d9cd19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain - Telecom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebd75439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the corresponding libraries for the Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d163143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55f956e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>6840-RESVB</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>24</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>84.80</td>\n",
       "      <td>1990.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>2234-XADUH</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>72</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>103.20</td>\n",
       "      <td>7362.9</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>4801-JZAZL</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.60</td>\n",
       "      <td>346.45</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>8361-LTMKD</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>74.40</td>\n",
       "      <td>306.6</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>3186-AJIEK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>66</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>105.65</td>\n",
       "      <td>6844.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7043 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customerID  gender  SeniorCitizen Partner Dependents  tenure  \\\n",
       "0     7590-VHVEG  Female              0     Yes         No       1   \n",
       "1     5575-GNVDE    Male              0      No         No      34   \n",
       "2     3668-QPYBK    Male              0      No         No       2   \n",
       "3     7795-CFOCW    Male              0      No         No      45   \n",
       "4     9237-HQITU  Female              0      No         No       2   \n",
       "...          ...     ...            ...     ...        ...     ...   \n",
       "7038  6840-RESVB    Male              0     Yes        Yes      24   \n",
       "7039  2234-XADUH  Female              0     Yes        Yes      72   \n",
       "7040  4801-JZAZL  Female              0     Yes        Yes      11   \n",
       "7041  8361-LTMKD    Male              1     Yes         No       4   \n",
       "7042  3186-AJIEK    Male              0      No         No      66   \n",
       "\n",
       "     PhoneService     MultipleLines InternetService OnlineSecurity  ...  \\\n",
       "0              No  No phone service             DSL             No  ...   \n",
       "1             Yes                No             DSL            Yes  ...   \n",
       "2             Yes                No             DSL            Yes  ...   \n",
       "3              No  No phone service             DSL            Yes  ...   \n",
       "4             Yes                No     Fiber optic             No  ...   \n",
       "...           ...               ...             ...            ...  ...   \n",
       "7038          Yes               Yes             DSL            Yes  ...   \n",
       "7039          Yes               Yes     Fiber optic             No  ...   \n",
       "7040           No  No phone service             DSL            Yes  ...   \n",
       "7041          Yes               Yes     Fiber optic             No  ...   \n",
       "7042          Yes                No     Fiber optic            Yes  ...   \n",
       "\n",
       "     DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n",
       "0                  No          No          No              No  Month-to-month   \n",
       "1                 Yes          No          No              No        One year   \n",
       "2                  No          No          No              No  Month-to-month   \n",
       "3                 Yes         Yes          No              No        One year   \n",
       "4                  No          No          No              No  Month-to-month   \n",
       "...               ...         ...         ...             ...             ...   \n",
       "7038              Yes         Yes         Yes             Yes        One year   \n",
       "7039              Yes          No         Yes             Yes        One year   \n",
       "7040               No          No          No              No  Month-to-month   \n",
       "7041               No          No          No              No  Month-to-month   \n",
       "7042              Yes         Yes         Yes             Yes        Two year   \n",
       "\n",
       "     PaperlessBilling              PaymentMethod MonthlyCharges  TotalCharges  \\\n",
       "0                 Yes           Electronic check          29.85         29.85   \n",
       "1                  No               Mailed check          56.95        1889.5   \n",
       "2                 Yes               Mailed check          53.85        108.15   \n",
       "3                  No  Bank transfer (automatic)          42.30       1840.75   \n",
       "4                 Yes           Electronic check          70.70        151.65   \n",
       "...               ...                        ...            ...           ...   \n",
       "7038              Yes               Mailed check          84.80        1990.5   \n",
       "7039              Yes    Credit card (automatic)         103.20        7362.9   \n",
       "7040              Yes           Electronic check          29.60        346.45   \n",
       "7041              Yes               Mailed check          74.40         306.6   \n",
       "7042              Yes  Bank transfer (automatic)         105.65        6844.5   \n",
       "\n",
       "     Churn  \n",
       "0       No  \n",
       "1       No  \n",
       "2      Yes  \n",
       "3       No  \n",
       "4      Yes  \n",
       "...    ...  \n",
       "7038    No  \n",
       "7039    No  \n",
       "7040    No  \n",
       "7041   Yes  \n",
       "7042    No  \n",
       "\n",
       "[7043 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer = pd.read_csv(r'D:\\Data science and AI\\Artificial Intelligence\\Assignments\\AI-Project\\customer_churn.csv')\n",
    "customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c97770ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb5ea4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   object \n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "customer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f2ba7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID          0\n",
       "gender              0\n",
       "SeniorCitizen       0\n",
       "Partner             0\n",
       "Dependents          0\n",
       "tenure              0\n",
       "PhoneService        0\n",
       "MultipleLines       0\n",
       "InternetService     0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        0\n",
       "DeviceProtection    0\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "Contract            0\n",
       "PaperlessBilling    0\n",
       "PaymentMethod       0\n",
       "MonthlyCharges      0\n",
       "TotalCharges        0\n",
       "Churn               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ced5f043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13400876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are no null values and duplicate values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5acad8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3555\n"
     ]
    }
   ],
   "source": [
    "Male_customers = (customer['gender']=='Male') # Number of Male customers\n",
    "print(sum(Male_customers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7aa0c83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2421\n"
     ]
    }
   ],
   "source": [
    "DSL_customers = (customer['InternetService']=='DSL') # Number of customers whose Internet Service is ‘DSL’\n",
    "print(sum(DSL_customers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18edd566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0390-DCFDQ</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>70.45</td>\n",
       "      <td>70.45</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2656-FMOKZ</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>74.45</td>\n",
       "      <td>1145.7</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>3197-ARFOY</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>19</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>105.00</td>\n",
       "      <td>2007.25</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>5760-WRAHC</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>69.75</td>\n",
       "      <td>1545.4</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>4933-IKULF</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>17</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>...</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>20.65</td>\n",
       "      <td>330.6</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     customerID  gender  SeniorCitizen Partner Dependents  tenure  \\\n",
       "139  0390-DCFDQ  Female              1     Yes         No       1   \n",
       "176  2656-FMOKZ  Female              1      No         No      15   \n",
       "267  3197-ARFOY  Female              1      No         No      19   \n",
       "451  5760-WRAHC  Female              1      No         No      22   \n",
       "470  4933-IKULF  Female              1      No         No      17   \n",
       "\n",
       "    PhoneService MultipleLines InternetService       OnlineSecurity  ...  \\\n",
       "139          Yes            No     Fiber optic                   No  ...   \n",
       "176          Yes           Yes     Fiber optic                   No  ...   \n",
       "267          Yes            No     Fiber optic                  Yes  ...   \n",
       "451          Yes            No             DSL                  Yes  ...   \n",
       "470          Yes            No              No  No internet service  ...   \n",
       "\n",
       "        DeviceProtection          TechSupport          StreamingTV  \\\n",
       "139                   No                   No                   No   \n",
       "176                   No                   No                   No   \n",
       "267                   No                  Yes                  Yes   \n",
       "451                  Yes                  Yes                   No   \n",
       "470  No internet service  No internet service  No internet service   \n",
       "\n",
       "         StreamingMovies        Contract PaperlessBilling PaymentMethod  \\\n",
       "139                   No  Month-to-month              Yes  Mailed check   \n",
       "176                   No  Month-to-month              Yes  Mailed check   \n",
       "267                  Yes  Month-to-month              Yes  Mailed check   \n",
       "451                  Yes  Month-to-month              Yes  Mailed check   \n",
       "470  No internet service        One year               No  Mailed check   \n",
       "\n",
       "    MonthlyCharges  TotalCharges Churn  \n",
       "139          70.45         70.45   Yes  \n",
       "176          74.45        1145.7   Yes  \n",
       "267         105.00       2007.25    No  \n",
       "451          69.75        1545.4    No  \n",
       "470          20.65         330.6    No  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all the Female senior citizens whose Payment Method is Mailed check & store the result in ‘new_customer’\n",
    "new_customer=customer[(customer['gender']=='Female') & (customer['SeniorCitizen']==1) & (customer['PaymentMethod']=='Mailed check')] \n",
    "new_customer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7efb1621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#customer['TotalCharges'] = customer['TotalCharges'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99152ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all those customers whose tenure is less than 10 months or their Total charges is less than 500$ & store the result in ‘new_customer’\n",
    "# new_customers=customer[(customer['tenure']<10) & (customer['TotalCharges']<500)] \n",
    "# new_customers.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ea81970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6013d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build a pie-chart to show the distribution of customers would be churning out\n",
    "names = customer[\"Churn\"].value_counts().keys().tolist() \n",
    "sizes= customer[\"Churn\"].value_counts().tolist()\n",
    "plt.pie(sizes,labels=names,autopct=\"%0.1f%%\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b383e925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build a bar-plot to show the distribution of ‘Internet Service’\n",
    "plt.bar(customer['InternetService'].value_counts().keys().tolist(),customer['InternetService'].value_counts().tolist(),color='orange') \n",
    "plt.xlabel('Categories of Internet Service') \n",
    "plt.ylabel('Count of categories')\n",
    "plt.title('Distribution of Internet Service') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d418e0",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fb54d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a. Build a sequential model using Keras, to find out if the customerwouldchurn or not, using\\n‘tenure’ as the feature and ‘Churn’ as the dependent/target column:\\ni. The visible/input layer should have 12 nodes with ‘Relu’ as activation function.\\nii. This model would have 1 hidden layer with 8 nodes and ‘Relu’ as activation function\\niii. Use ‘Adam’ as the optimization algorithm \\niv. Fit the model on the train set, with number of epochs to be 150\\nv. Predict the values on the test set and build a confusion matrix \\nvi. Plot the ‘Accuracy vs Epochs’ graph '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''a. Build a sequential model using Keras, to find out if the customerwouldchurn or not, using\n",
    "‘tenure’ as the feature and ‘Churn’ as the dependent/target column:\n",
    "i. The visible/input layer should have 12 nodes with ‘Relu’ as activation function.\n",
    "ii. This model would have 1 hidden layer with 8 nodes and ‘Relu’ as activation function\n",
    "iii. Use ‘Adam’ as the optimization algorithm \n",
    "iv. Fit the model on the train set, with number of epochs to be 150\n",
    "v. Predict the values on the test set and build a confusion matrix \n",
    "vi. Plot the ‘Accuracy vs Epochs’ graph '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58350cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to convert all the object datatypes into numbers using LabelEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65bba48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=customer.columns\n",
    "obj_cols=[]\n",
    "for col in columns:\n",
    "    if customer[col].dtype==\"object\":\n",
    "        obj_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "992f2fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['customerID',\n",
       " 'gender',\n",
       " 'Partner',\n",
       " 'Dependents',\n",
       " 'PhoneService',\n",
       " 'MultipleLines',\n",
       " 'InternetService',\n",
       " 'OnlineSecurity',\n",
       " 'OnlineBackup',\n",
       " 'DeviceProtection',\n",
       " 'TechSupport',\n",
       " 'StreamingTV',\n",
       " 'StreamingMovies',\n",
       " 'Contract',\n",
       " 'PaperlessBilling',\n",
       " 'PaymentMethod',\n",
       " 'TotalCharges',\n",
       " 'Churn']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9fde2be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "for i in obj_cols:\n",
    "    customer[i]=le.fit_transform(customer[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5867e8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.85</td>\n",
       "      <td>2505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3962</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2564</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>53.85</td>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5535</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6511</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>70.70</td>\n",
       "      <td>925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>4853</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>84.80</td>\n",
       "      <td>1597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>1525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>103.20</td>\n",
       "      <td>5698</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>3367</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.60</td>\n",
       "      <td>2994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>5934</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>74.40</td>\n",
       "      <td>2660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>2226</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>105.65</td>\n",
       "      <td>5407</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7043 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customerID  gender  SeniorCitizen  Partner  Dependents  tenure  \\\n",
       "0           5375       0              0        1           0       1   \n",
       "1           3962       1              0        0           0      34   \n",
       "2           2564       1              0        0           0       2   \n",
       "3           5535       1              0        0           0      45   \n",
       "4           6511       0              0        0           0       2   \n",
       "...          ...     ...            ...      ...         ...     ...   \n",
       "7038        4853       1              0        1           1      24   \n",
       "7039        1525       0              0        1           1      72   \n",
       "7040        3367       0              0        1           1      11   \n",
       "7041        5934       1              1        1           0       4   \n",
       "7042        2226       1              0        0           0      66   \n",
       "\n",
       "      PhoneService  MultipleLines  InternetService  OnlineSecurity  ...  \\\n",
       "0                0              1                0               0  ...   \n",
       "1                1              0                0               2  ...   \n",
       "2                1              0                0               2  ...   \n",
       "3                0              1                0               2  ...   \n",
       "4                1              0                1               0  ...   \n",
       "...            ...            ...              ...             ...  ...   \n",
       "7038             1              2                0               2  ...   \n",
       "7039             1              2                1               0  ...   \n",
       "7040             0              1                0               2  ...   \n",
       "7041             1              2                1               0  ...   \n",
       "7042             1              0                1               2  ...   \n",
       "\n",
       "      DeviceProtection  TechSupport  StreamingTV  StreamingMovies  Contract  \\\n",
       "0                    0            0            0                0         0   \n",
       "1                    2            0            0                0         1   \n",
       "2                    0            0            0                0         0   \n",
       "3                    2            2            0                0         1   \n",
       "4                    0            0            0                0         0   \n",
       "...                ...          ...          ...              ...       ...   \n",
       "7038                 2            2            2                2         1   \n",
       "7039                 2            0            2                2         1   \n",
       "7040                 0            0            0                0         0   \n",
       "7041                 0            0            0                0         0   \n",
       "7042                 2            2            2                2         2   \n",
       "\n",
       "      PaperlessBilling  PaymentMethod  MonthlyCharges  TotalCharges  Churn  \n",
       "0                    1              2           29.85          2505      0  \n",
       "1                    0              3           56.95          1466      0  \n",
       "2                    1              3           53.85           157      1  \n",
       "3                    0              0           42.30          1400      0  \n",
       "4                    1              2           70.70           925      1  \n",
       "...                ...            ...             ...           ...    ...  \n",
       "7038                 1              3           84.80          1597      0  \n",
       "7039                 1              1          103.20          5698      0  \n",
       "7040                 1              2           29.60          2994      0  \n",
       "7041                 1              3           74.40          2660      1  \n",
       "7042                 1              0          105.65          5407      0  \n",
       "\n",
       "[7043 rows x 21 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fb3e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=customer[['tenure']] \n",
    "y=customer[['Churn']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4aa2d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ffabe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7ee69f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "model.add(Dense(12, input_dim=1, activation='relu')) \n",
    "model.add(Dense(8, activation='relu')) \n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6f5f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd432091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 2.0583 - accuracy: 0.7371 - val_loss: 0.7660 - val_accuracy: 0.7549\n",
      "Epoch 2/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7444 - val_loss: 0.5135 - val_accuracy: 0.7397\n",
      "Epoch 3/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7509 - val_loss: 0.5108 - val_accuracy: 0.7463\n",
      "Epoch 4/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7548 - val_loss: 0.5106 - val_accuracy: 0.7459\n",
      "Epoch 5/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7525 - val_loss: 0.5114 - val_accuracy: 0.7459\n",
      "Epoch 6/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7531 - val_loss: 0.5098 - val_accuracy: 0.7549\n",
      "Epoch 7/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7544 - val_loss: 0.5097 - val_accuracy: 0.7549\n",
      "Epoch 8/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7525 - val_loss: 0.5100 - val_accuracy: 0.7539\n",
      "Epoch 9/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7554 - val_loss: 0.5098 - val_accuracy: 0.7539\n",
      "Epoch 10/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7499 - val_loss: 0.5108 - val_accuracy: 0.7269\n",
      "Epoch 11/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7357 - val_loss: 0.5109 - val_accuracy: 0.7269\n",
      "Epoch 12/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7357 - val_loss: 0.5123 - val_accuracy: 0.7269\n",
      "Epoch 13/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7357 - val_loss: 0.5104 - val_accuracy: 0.7269\n",
      "Epoch 14/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7357 - val_loss: 0.5105 - val_accuracy: 0.7269\n",
      "Epoch 15/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7357 - val_loss: 0.5105 - val_accuracy: 0.7269\n",
      "Epoch 16/150\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.5131 - accuracy: 0.7373 - val_loss: 0.5129 - val_accuracy: 0.7283\n",
      "Epoch 17/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7373 - val_loss: 0.5104 - val_accuracy: 0.7283\n",
      "Epoch 18/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7373 - val_loss: 0.5103 - val_accuracy: 0.7283\n",
      "Epoch 19/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7373 - val_loss: 0.5115 - val_accuracy: 0.7283\n",
      "Epoch 20/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7373 - val_loss: 0.5115 - val_accuracy: 0.7283\n",
      "Epoch 21/150\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.5135 - accuracy: 0.7373 - val_loss: 0.5102 - val_accuracy: 0.7283\n",
      "Epoch 22/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7373 - val_loss: 0.5099 - val_accuracy: 0.7283\n",
      "Epoch 23/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7373 - val_loss: 0.5121 - val_accuracy: 0.7283\n",
      "Epoch 24/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7373 - val_loss: 0.5099 - val_accuracy: 0.7283\n",
      "Epoch 25/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7373 - val_loss: 0.5100 - val_accuracy: 0.7283\n",
      "Epoch 26/150\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.5121 - accuracy: 0.7373 - val_loss: 0.5116 - val_accuracy: 0.7283\n",
      "Epoch 27/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7373 - val_loss: 0.5149 - val_accuracy: 0.7283\n",
      "Epoch 28/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7373 - val_loss: 0.5097 - val_accuracy: 0.7283\n",
      "Epoch 29/150\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.5124 - accuracy: 0.7373 - val_loss: 0.5099 - val_accuracy: 0.7283\n",
      "Epoch 30/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7373 - val_loss: 0.5097 - val_accuracy: 0.7283\n",
      "Epoch 31/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7373 - val_loss: 0.5102 - val_accuracy: 0.7283\n",
      "Epoch 32/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7373 - val_loss: 0.5097 - val_accuracy: 0.7283\n",
      "Epoch 33/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7373 - val_loss: 0.5100 - val_accuracy: 0.7283\n",
      "Epoch 34/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7373 - val_loss: 0.5123 - val_accuracy: 0.7283\n",
      "Epoch 35/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7373 - val_loss: 0.5102 - val_accuracy: 0.7283\n",
      "Epoch 36/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7373 - val_loss: 0.5100 - val_accuracy: 0.7283\n",
      "Epoch 37/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7373 - val_loss: 0.5122 - val_accuracy: 0.7283\n",
      "Epoch 38/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7373 - val_loss: 0.5128 - val_accuracy: 0.7283\n",
      "Epoch 39/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7373 - val_loss: 0.5109 - val_accuracy: 0.7283\n",
      "Epoch 40/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7373 - val_loss: 0.5096 - val_accuracy: 0.7283\n",
      "Epoch 41/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7373 - val_loss: 0.5121 - val_accuracy: 0.7283\n",
      "Epoch 42/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7373 - val_loss: 0.5096 - val_accuracy: 0.7283\n",
      "Epoch 43/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7373 - val_loss: 0.5109 - val_accuracy: 0.7283\n",
      "Epoch 44/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7373 - val_loss: 0.5096 - val_accuracy: 0.7283\n",
      "Epoch 45/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7373 - val_loss: 0.5095 - val_accuracy: 0.7283\n",
      "Epoch 46/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7373 - val_loss: 0.5127 - val_accuracy: 0.7283\n",
      "Epoch 47/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7373 - val_loss: 0.5094 - val_accuracy: 0.7283\n",
      "Epoch 48/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7373 - val_loss: 0.5099 - val_accuracy: 0.7283\n",
      "Epoch 49/150\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.5125 - accuracy: 0.7373 - val_loss: 0.5158 - val_accuracy: 0.7283\n",
      "Epoch 50/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7373 - val_loss: 0.5105 - val_accuracy: 0.7283\n",
      "Epoch 51/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7373 - val_loss: 0.5133 - val_accuracy: 0.7283\n",
      "Epoch 52/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7373 - val_loss: 0.5098 - val_accuracy: 0.7283\n",
      "Epoch 53/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7373 - val_loss: 0.5094 - val_accuracy: 0.7283\n",
      "Epoch 54/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7373 - val_loss: 0.5094 - val_accuracy: 0.7283\n",
      "Epoch 55/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7373 - val_loss: 0.5092 - val_accuracy: 0.7283\n",
      "Epoch 56/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7373 - val_loss: 0.5117 - val_accuracy: 0.7283\n",
      "Epoch 57/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7373 - val_loss: 0.5100 - val_accuracy: 0.7283\n",
      "Epoch 58/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7373 - val_loss: 0.5092 - val_accuracy: 0.7283\n",
      "Epoch 59/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7373 - val_loss: 0.5099 - val_accuracy: 0.7283\n",
      "Epoch 60/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7373 - val_loss: 0.5095 - val_accuracy: 0.7283\n",
      "Epoch 61/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7373 - val_loss: 0.5092 - val_accuracy: 0.7283\n",
      "Epoch 62/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7373 - val_loss: 0.5099 - val_accuracy: 0.7283\n",
      "Epoch 63/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7373 - val_loss: 0.5096 - val_accuracy: 0.7283\n",
      "Epoch 64/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7373 - val_loss: 0.5091 - val_accuracy: 0.7283\n",
      "Epoch 65/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7373 - val_loss: 0.5109 - val_accuracy: 0.7283\n",
      "Epoch 66/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7373 - val_loss: 0.5132 - val_accuracy: 0.7283\n",
      "Epoch 67/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7373 - val_loss: 0.5107 - val_accuracy: 0.7283\n",
      "Epoch 68/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7373 - val_loss: 0.5106 - val_accuracy: 0.7283\n",
      "Epoch 69/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7373 - val_loss: 0.5095 - val_accuracy: 0.7283\n",
      "Epoch 70/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7379 - val_loss: 0.5094 - val_accuracy: 0.7283\n",
      "Epoch 71/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7373 - val_loss: 0.5109 - val_accuracy: 0.7283\n",
      "Epoch 72/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7373 - val_loss: 0.5097 - val_accuracy: 0.7283\n",
      "Epoch 73/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7373 - val_loss: 0.5106 - val_accuracy: 0.7283\n",
      "Epoch 74/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7373 - val_loss: 0.5103 - val_accuracy: 0.7283\n",
      "Epoch 75/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7373 - val_loss: 0.5092 - val_accuracy: 0.7283\n",
      "Epoch 76/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7373 - val_loss: 0.5092 - val_accuracy: 0.7283\n",
      "Epoch 77/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7373 - val_loss: 0.5092 - val_accuracy: 0.7283\n",
      "Epoch 78/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7373 - val_loss: 0.5097 - val_accuracy: 0.7283\n",
      "Epoch 79/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7373 - val_loss: 0.5117 - val_accuracy: 0.7283\n",
      "Epoch 80/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7373 - val_loss: 0.5101 - val_accuracy: 0.7283\n",
      "Epoch 81/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7373 - val_loss: 0.5105 - val_accuracy: 0.7283\n",
      "Epoch 82/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7373 - val_loss: 0.5097 - val_accuracy: 0.7283\n",
      "Epoch 83/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7373 - val_loss: 0.5097 - val_accuracy: 0.7283\n",
      "Epoch 84/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7375 - val_loss: 0.5091 - val_accuracy: 0.7283\n",
      "Epoch 85/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7373 - val_loss: 0.5096 - val_accuracy: 0.7283\n",
      "Epoch 86/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7373 - val_loss: 0.5095 - val_accuracy: 0.7283\n",
      "Epoch 87/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7373 - val_loss: 0.5093 - val_accuracy: 0.7283\n",
      "Epoch 88/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7373 - val_loss: 0.5108 - val_accuracy: 0.7283\n",
      "Epoch 89/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7373 - val_loss: 0.5123 - val_accuracy: 0.7283\n",
      "Epoch 90/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7373 - val_loss: 0.5093 - val_accuracy: 0.7283\n",
      "Epoch 91/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7373 - val_loss: 0.5091 - val_accuracy: 0.7283\n",
      "Epoch 92/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7373 - val_loss: 0.5102 - val_accuracy: 0.7283\n",
      "Epoch 93/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7373 - val_loss: 0.5093 - val_accuracy: 0.7283\n",
      "Epoch 94/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7373 - val_loss: 0.5104 - val_accuracy: 0.7283\n",
      "Epoch 95/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7373 - val_loss: 0.5094 - val_accuracy: 0.7283\n",
      "Epoch 96/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7373 - val_loss: 0.5096 - val_accuracy: 0.7283\n",
      "Epoch 97/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7373 - val_loss: 0.5101 - val_accuracy: 0.7283\n",
      "Epoch 98/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7373 - val_loss: 0.5093 - val_accuracy: 0.7283\n",
      "Epoch 99/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7373 - val_loss: 0.5093 - val_accuracy: 0.7283\n",
      "Epoch 100/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7373 - val_loss: 0.5099 - val_accuracy: 0.7283\n",
      "Epoch 101/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7373 - val_loss: 0.5111 - val_accuracy: 0.7283\n",
      "Epoch 102/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7373 - val_loss: 0.5118 - val_accuracy: 0.7283\n",
      "Epoch 103/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7373 - val_loss: 0.5091 - val_accuracy: 0.7283\n",
      "Epoch 104/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7373 - val_loss: 0.5091 - val_accuracy: 0.7283\n",
      "Epoch 105/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7373 - val_loss: 0.5095 - val_accuracy: 0.7283\n",
      "Epoch 106/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7373 - val_loss: 0.5091 - val_accuracy: 0.7283\n",
      "Epoch 107/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7373 - val_loss: 0.5092 - val_accuracy: 0.7283\n",
      "Epoch 108/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7373 - val_loss: 0.5110 - val_accuracy: 0.7283\n",
      "Epoch 109/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7373 - val_loss: 0.5113 - val_accuracy: 0.7283\n",
      "Epoch 110/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7373 - val_loss: 0.5094 - val_accuracy: 0.7283\n",
      "Epoch 111/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7373 - val_loss: 0.5126 - val_accuracy: 0.7283\n",
      "Epoch 112/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7373 - val_loss: 0.5093 - val_accuracy: 0.7283\n",
      "Epoch 113/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7373 - val_loss: 0.5092 - val_accuracy: 0.7283\n",
      "Epoch 114/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7373 - val_loss: 0.5097 - val_accuracy: 0.7283\n",
      "Epoch 115/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7373 - val_loss: 0.5091 - val_accuracy: 0.7283\n",
      "Epoch 116/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7373 - val_loss: 0.5091 - val_accuracy: 0.7283\n",
      "Epoch 117/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7373 - val_loss: 0.5097 - val_accuracy: 0.7283\n",
      "Epoch 118/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7373 - val_loss: 0.5091 - val_accuracy: 0.7283\n",
      "Epoch 119/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7373 - val_loss: 0.5092 - val_accuracy: 0.7283\n",
      "Epoch 120/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7373 - val_loss: 0.5093 - val_accuracy: 0.7283\n",
      "Epoch 121/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7373 - val_loss: 0.5091 - val_accuracy: 0.7283\n",
      "Epoch 122/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7373 - val_loss: 0.5098 - val_accuracy: 0.7283\n",
      "Epoch 123/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7373 - val_loss: 0.5098 - val_accuracy: 0.7283\n",
      "Epoch 124/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7373 - val_loss: 0.5110 - val_accuracy: 0.7283\n",
      "Epoch 125/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7373 - val_loss: 0.5092 - val_accuracy: 0.7283\n",
      "Epoch 126/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7373 - val_loss: 0.5099 - val_accuracy: 0.7283\n",
      "Epoch 127/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7373 - val_loss: 0.5092 - val_accuracy: 0.7283\n",
      "Epoch 128/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7373 - val_loss: 0.5094 - val_accuracy: 0.7283\n",
      "Epoch 129/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7373 - val_loss: 0.5102 - val_accuracy: 0.7283\n",
      "Epoch 130/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7373 - val_loss: 0.5091 - val_accuracy: 0.7283\n",
      "Epoch 131/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7373 - val_loss: 0.5090 - val_accuracy: 0.7283\n",
      "Epoch 132/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7373 - val_loss: 0.5092 - val_accuracy: 0.7283\n",
      "Epoch 133/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7373 - val_loss: 0.5096 - val_accuracy: 0.7283\n",
      "Epoch 134/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7373 - val_loss: 0.5092 - val_accuracy: 0.7283\n",
      "Epoch 135/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7373 - val_loss: 0.5117 - val_accuracy: 0.7283\n",
      "Epoch 136/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7373 - val_loss: 0.5130 - val_accuracy: 0.7283\n",
      "Epoch 137/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7373 - val_loss: 0.5095 - val_accuracy: 0.7283\n",
      "Epoch 138/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7373 - val_loss: 0.5097 - val_accuracy: 0.7283\n",
      "Epoch 139/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7373 - val_loss: 0.5094 - val_accuracy: 0.7283\n",
      "Epoch 140/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7373 - val_loss: 0.5093 - val_accuracy: 0.7283\n",
      "Epoch 141/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7373 - val_loss: 0.5100 - val_accuracy: 0.7283\n",
      "Epoch 142/150\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.5104 - accuracy: 0.7373 - val_loss: 0.5110 - val_accuracy: 0.7283\n",
      "Epoch 143/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7373 - val_loss: 0.5097 - val_accuracy: 0.7283\n",
      "Epoch 144/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7373 - val_loss: 0.5093 - val_accuracy: 0.7283\n",
      "Epoch 145/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7373 - val_loss: 0.5091 - val_accuracy: 0.7283\n",
      "Epoch 146/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7373 - val_loss: 0.5091 - val_accuracy: 0.7283\n",
      "Epoch 147/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7373 - val_loss: 0.5098 - val_accuracy: 0.7283\n",
      "Epoch 148/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7373 - val_loss: 0.5091 - val_accuracy: 0.7283\n",
      "Epoch 149/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7373 - val_loss: 0.5093 - val_accuracy: 0.7283\n",
      "Epoch 150/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7373 - val_loss: 0.5092 - val_accuracy: 0.7283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1aa1a990a30>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=150,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d67ee483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(model.history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "187945e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y_pred=model.predict(y_test) \\nfrom sklearn.metrics import confusion_matrix \\nconfusion_matrix(y_test,y_pred)'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''y_pred=model.predict(y_test) \n",
    "from sklearn.metrics import confusion_matrix \n",
    "confusion_matrix(y_test,y_pred)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25c9214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "plt.plot(model.history.history['acc']) \n",
    "plt.plot(model.history.history['val_acc']) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a086fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(model.history.history['acc']) \n",
    "#plt.plot(model.history.history['val_acc']) \n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a08f9962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc1ce946",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "model.add(Dense(12, input_dim=1, activation='relu')) \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(8, activation='relu')) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "978d64c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3287d85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 1.8519 - accuracy: 0.5706 - val_loss: 0.7043 - val_accuracy: 0.7283\n",
      "Epoch 2/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9382 - accuracy: 0.6398 - val_loss: 0.5394 - val_accuracy: 0.7283\n",
      "Epoch 3/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7224 - accuracy: 0.6791 - val_loss: 0.5155 - val_accuracy: 0.7283\n",
      "Epoch 4/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.7067 - val_loss: 0.5369 - val_accuracy: 0.7283\n",
      "Epoch 5/150\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.6179 - accuracy: 0.7172 - val_loss: 0.5312 - val_accuracy: 0.7283\n",
      "Epoch 6/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.7193 - val_loss: 0.5359 - val_accuracy: 0.7283\n",
      "Epoch 7/150\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.5799 - accuracy: 0.7235 - val_loss: 0.5395 - val_accuracy: 0.7283\n",
      "Epoch 8/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.7239 - val_loss: 0.5430 - val_accuracy: 0.7283\n",
      "Epoch 9/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7312 - val_loss: 0.5349 - val_accuracy: 0.7283\n",
      "Epoch 10/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7310 - val_loss: 0.5314 - val_accuracy: 0.7283\n",
      "Epoch 11/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7341 - val_loss: 0.5244 - val_accuracy: 0.7283\n",
      "Epoch 12/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7341 - val_loss: 0.5241 - val_accuracy: 0.7283\n",
      "Epoch 13/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7353 - val_loss: 0.5314 - val_accuracy: 0.7283\n",
      "Epoch 14/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7359 - val_loss: 0.5258 - val_accuracy: 0.7283\n",
      "Epoch 15/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7351 - val_loss: 0.5214 - val_accuracy: 0.7283\n",
      "Epoch 16/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7361 - val_loss: 0.5247 - val_accuracy: 0.7283\n",
      "Epoch 17/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7363 - val_loss: 0.5256 - val_accuracy: 0.7283\n",
      "Epoch 18/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7367 - val_loss: 0.5187 - val_accuracy: 0.7283\n",
      "Epoch 19/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7369 - val_loss: 0.5243 - val_accuracy: 0.7283\n",
      "Epoch 20/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7365 - val_loss: 0.5175 - val_accuracy: 0.7283\n",
      "Epoch 21/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7369 - val_loss: 0.5190 - val_accuracy: 0.7283\n",
      "Epoch 22/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7373 - val_loss: 0.5163 - val_accuracy: 0.7283\n",
      "Epoch 23/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7359 - val_loss: 0.5161 - val_accuracy: 0.7283\n",
      "Epoch 24/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7367 - val_loss: 0.5208 - val_accuracy: 0.7283\n",
      "Epoch 25/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7363 - val_loss: 0.5183 - val_accuracy: 0.7283\n",
      "Epoch 26/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7371 - val_loss: 0.5187 - val_accuracy: 0.7283\n",
      "Epoch 27/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7365 - val_loss: 0.5195 - val_accuracy: 0.7283\n",
      "Epoch 28/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7373 - val_loss: 0.5176 - val_accuracy: 0.7283\n",
      "Epoch 29/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7363 - val_loss: 0.5190 - val_accuracy: 0.7283\n",
      "Epoch 30/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7373 - val_loss: 0.5162 - val_accuracy: 0.7283\n",
      "Epoch 31/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7373 - val_loss: 0.5164 - val_accuracy: 0.7283\n",
      "Epoch 32/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7373 - val_loss: 0.5239 - val_accuracy: 0.7283\n",
      "Epoch 33/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7373 - val_loss: 0.5200 - val_accuracy: 0.7283\n",
      "Epoch 34/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7373 - val_loss: 0.5212 - val_accuracy: 0.7283\n",
      "Epoch 35/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7371 - val_loss: 0.5211 - val_accuracy: 0.7283\n",
      "Epoch 36/150\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.5300 - accuracy: 0.7373 - val_loss: 0.5193 - val_accuracy: 0.7283\n",
      "Epoch 37/150\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.5282 - accuracy: 0.7373 - val_loss: 0.5194 - val_accuracy: 0.7283\n",
      "Epoch 38/150\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.5262 - accuracy: 0.7371 - val_loss: 0.5157 - val_accuracy: 0.7283\n",
      "Epoch 39/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7371 - val_loss: 0.5174 - val_accuracy: 0.7283\n",
      "Epoch 40/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7373 - val_loss: 0.5203 - val_accuracy: 0.7283\n",
      "Epoch 41/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7373 - val_loss: 0.5166 - val_accuracy: 0.7283\n",
      "Epoch 42/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7371 - val_loss: 0.5176 - val_accuracy: 0.7283\n",
      "Epoch 43/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7373 - val_loss: 0.5148 - val_accuracy: 0.7283\n",
      "Epoch 44/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7373 - val_loss: 0.5178 - val_accuracy: 0.7283\n",
      "Epoch 45/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7373 - val_loss: 0.5172 - val_accuracy: 0.7283\n",
      "Epoch 46/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7373 - val_loss: 0.5155 - val_accuracy: 0.7283\n",
      "Epoch 47/150\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.5262 - accuracy: 0.7373 - val_loss: 0.5170 - val_accuracy: 0.7283\n",
      "Epoch 48/150\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.5256 - accuracy: 0.7371 - val_loss: 0.5194 - val_accuracy: 0.7283\n",
      "Epoch 49/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7371 - val_loss: 0.5213 - val_accuracy: 0.7283\n",
      "Epoch 50/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7373 - val_loss: 0.5169 - val_accuracy: 0.7283\n",
      "Epoch 51/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7373 - val_loss: 0.5175 - val_accuracy: 0.7283\n",
      "Epoch 52/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7373 - val_loss: 0.5167 - val_accuracy: 0.7283\n",
      "Epoch 53/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7373 - val_loss: 0.5173 - val_accuracy: 0.7283\n",
      "Epoch 54/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7373 - val_loss: 0.5156 - val_accuracy: 0.7283\n",
      "Epoch 55/150\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.5247 - accuracy: 0.7373 - val_loss: 0.5203 - val_accuracy: 0.7283\n",
      "Epoch 56/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7373 - val_loss: 0.5187 - val_accuracy: 0.7283\n",
      "Epoch 57/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7373 - val_loss: 0.5179 - val_accuracy: 0.7283\n",
      "Epoch 58/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7373 - val_loss: 0.5180 - val_accuracy: 0.7283\n",
      "Epoch 59/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7373 - val_loss: 0.5185 - val_accuracy: 0.7283\n",
      "Epoch 60/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7373 - val_loss: 0.5198 - val_accuracy: 0.7283\n",
      "Epoch 61/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7373 - val_loss: 0.5204 - val_accuracy: 0.7283\n",
      "Epoch 62/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7373 - val_loss: 0.5213 - val_accuracy: 0.7283\n",
      "Epoch 63/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7373 - val_loss: 0.5167 - val_accuracy: 0.7283\n",
      "Epoch 64/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7373 - val_loss: 0.5159 - val_accuracy: 0.7283\n",
      "Epoch 65/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7373 - val_loss: 0.5165 - val_accuracy: 0.7283\n",
      "Epoch 66/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7373 - val_loss: 0.5229 - val_accuracy: 0.7283\n",
      "Epoch 67/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7373 - val_loss: 0.5158 - val_accuracy: 0.7283\n",
      "Epoch 68/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7373 - val_loss: 0.5257 - val_accuracy: 0.7283\n",
      "Epoch 69/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7373 - val_loss: 0.5169 - val_accuracy: 0.7283\n",
      "Epoch 70/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7373 - val_loss: 0.5162 - val_accuracy: 0.7283\n",
      "Epoch 71/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7373 - val_loss: 0.5141 - val_accuracy: 0.7283\n",
      "Epoch 72/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7373 - val_loss: 0.5187 - val_accuracy: 0.7283\n",
      "Epoch 73/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7373 - val_loss: 0.5207 - val_accuracy: 0.7283\n",
      "Epoch 74/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7373 - val_loss: 0.5152 - val_accuracy: 0.7283\n",
      "Epoch 75/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7373 - val_loss: 0.5180 - val_accuracy: 0.7283\n",
      "Epoch 76/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7373 - val_loss: 0.5187 - val_accuracy: 0.7283\n",
      "Epoch 77/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7373 - val_loss: 0.5145 - val_accuracy: 0.7283\n",
      "Epoch 78/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7373 - val_loss: 0.5164 - val_accuracy: 0.7283\n",
      "Epoch 79/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7373 - val_loss: 0.5165 - val_accuracy: 0.7283\n",
      "Epoch 80/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7373 - val_loss: 0.5172 - val_accuracy: 0.7283\n",
      "Epoch 81/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7373 - val_loss: 0.5184 - val_accuracy: 0.7283\n",
      "Epoch 82/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7373 - val_loss: 0.5171 - val_accuracy: 0.7283\n",
      "Epoch 83/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7373 - val_loss: 0.5216 - val_accuracy: 0.7283\n",
      "Epoch 84/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7373 - val_loss: 0.5193 - val_accuracy: 0.7283\n",
      "Epoch 85/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7373 - val_loss: 0.5165 - val_accuracy: 0.7283\n",
      "Epoch 86/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7373 - val_loss: 0.5177 - val_accuracy: 0.7283\n",
      "Epoch 87/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7373 - val_loss: 0.5194 - val_accuracy: 0.7283\n",
      "Epoch 88/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7373 - val_loss: 0.5196 - val_accuracy: 0.7283\n",
      "Epoch 89/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7373 - val_loss: 0.5175 - val_accuracy: 0.7283\n",
      "Epoch 90/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7373 - val_loss: 0.5194 - val_accuracy: 0.7283\n",
      "Epoch 91/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7373 - val_loss: 0.5198 - val_accuracy: 0.7283\n",
      "Epoch 92/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7373 - val_loss: 0.5168 - val_accuracy: 0.7283\n",
      "Epoch 93/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7373 - val_loss: 0.5158 - val_accuracy: 0.7283\n",
      "Epoch 94/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7373 - val_loss: 0.5188 - val_accuracy: 0.7283\n",
      "Epoch 95/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7373 - val_loss: 0.5154 - val_accuracy: 0.7283\n",
      "Epoch 96/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7373 - val_loss: 0.5149 - val_accuracy: 0.7283\n",
      "Epoch 97/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7373 - val_loss: 0.5190 - val_accuracy: 0.7283\n",
      "Epoch 98/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7373 - val_loss: 0.5158 - val_accuracy: 0.7283\n",
      "Epoch 99/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7373 - val_loss: 0.5181 - val_accuracy: 0.7283\n",
      "Epoch 100/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7373 - val_loss: 0.5170 - val_accuracy: 0.7283\n",
      "Epoch 101/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7373 - val_loss: 0.5225 - val_accuracy: 0.7283\n",
      "Epoch 102/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7373 - val_loss: 0.5161 - val_accuracy: 0.7283\n",
      "Epoch 103/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7373 - val_loss: 0.5157 - val_accuracy: 0.7283\n",
      "Epoch 104/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7373 - val_loss: 0.5186 - val_accuracy: 0.7283\n",
      "Epoch 105/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7373 - val_loss: 0.5187 - val_accuracy: 0.7283\n",
      "Epoch 106/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7373 - val_loss: 0.5185 - val_accuracy: 0.7283\n",
      "Epoch 107/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7373 - val_loss: 0.5174 - val_accuracy: 0.7283\n",
      "Epoch 108/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7373 - val_loss: 0.5186 - val_accuracy: 0.7283\n",
      "Epoch 109/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7373 - val_loss: 0.5188 - val_accuracy: 0.7283\n",
      "Epoch 110/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7373 - val_loss: 0.5212 - val_accuracy: 0.7283\n",
      "Epoch 111/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7373 - val_loss: 0.5171 - val_accuracy: 0.7283\n",
      "Epoch 112/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7373 - val_loss: 0.5149 - val_accuracy: 0.7283\n",
      "Epoch 113/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7373 - val_loss: 0.5152 - val_accuracy: 0.7283\n",
      "Epoch 114/150\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.5236 - accuracy: 0.7373 - val_loss: 0.5179 - val_accuracy: 0.7283\n",
      "Epoch 115/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7373 - val_loss: 0.5216 - val_accuracy: 0.7283\n",
      "Epoch 116/150\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.5259 - accuracy: 0.7373 - val_loss: 0.5237 - val_accuracy: 0.7283\n",
      "Epoch 117/150\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.5261 - accuracy: 0.7373 - val_loss: 0.5165 - val_accuracy: 0.7283\n",
      "Epoch 118/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7373 - val_loss: 0.5216 - val_accuracy: 0.7283\n",
      "Epoch 119/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7373 - val_loss: 0.5210 - val_accuracy: 0.7283\n",
      "Epoch 120/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7373 - val_loss: 0.5173 - val_accuracy: 0.7283\n",
      "Epoch 121/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7373 - val_loss: 0.5159 - val_accuracy: 0.7283\n",
      "Epoch 122/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7373 - val_loss: 0.5187 - val_accuracy: 0.7283\n",
      "Epoch 123/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7373 - val_loss: 0.5227 - val_accuracy: 0.7283\n",
      "Epoch 124/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7373 - val_loss: 0.5211 - val_accuracy: 0.7283\n",
      "Epoch 125/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7373 - val_loss: 0.5166 - val_accuracy: 0.7283\n",
      "Epoch 126/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7373 - val_loss: 0.5195 - val_accuracy: 0.7283\n",
      "Epoch 127/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7373 - val_loss: 0.5192 - val_accuracy: 0.7283\n",
      "Epoch 128/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7373 - val_loss: 0.5196 - val_accuracy: 0.7283\n",
      "Epoch 129/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7373 - val_loss: 0.5212 - val_accuracy: 0.7283\n",
      "Epoch 130/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7373 - val_loss: 0.5161 - val_accuracy: 0.7283\n",
      "Epoch 131/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7373 - val_loss: 0.5157 - val_accuracy: 0.7283\n",
      "Epoch 132/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7373 - val_loss: 0.5155 - val_accuracy: 0.7283\n",
      "Epoch 133/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7373 - val_loss: 0.5193 - val_accuracy: 0.7283\n",
      "Epoch 134/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7373 - val_loss: 0.5210 - val_accuracy: 0.7283\n",
      "Epoch 135/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7373 - val_loss: 0.5163 - val_accuracy: 0.7283\n",
      "Epoch 136/150\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.5279 - accuracy: 0.7373 - val_loss: 0.5176 - val_accuracy: 0.7283\n",
      "Epoch 137/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7373 - val_loss: 0.5168 - val_accuracy: 0.7283\n",
      "Epoch 138/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7373 - val_loss: 0.5206 - val_accuracy: 0.7283\n",
      "Epoch 139/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7373 - val_loss: 0.5151 - val_accuracy: 0.7283\n",
      "Epoch 140/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7373 - val_loss: 0.5185 - val_accuracy: 0.7283\n",
      "Epoch 141/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7373 - val_loss: 0.5197 - val_accuracy: 0.7283\n",
      "Epoch 142/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7373 - val_loss: 0.5168 - val_accuracy: 0.7283\n",
      "Epoch 143/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7373 - val_loss: 0.5196 - val_accuracy: 0.7283\n",
      "Epoch 144/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7373 - val_loss: 0.5167 - val_accuracy: 0.7283\n",
      "Epoch 145/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7373 - val_loss: 0.5186 - val_accuracy: 0.7283\n",
      "Epoch 146/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7373 - val_loss: 0.5168 - val_accuracy: 0.7283\n",
      "Epoch 147/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7373 - val_loss: 0.5213 - val_accuracy: 0.7283\n",
      "Epoch 148/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7373 - val_loss: 0.5195 - val_accuracy: 0.7283\n",
      "Epoch 149/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7373 - val_loss: 0.5199 - val_accuracy: 0.7283\n",
      "Epoch 150/150\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.5195 - accuracy: 0.7373 - val_loss: 0.5147 - val_accuracy: 0.7283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1aa1bc053a0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=150,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b4aa7484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y_pred = model.predict(x_test) \\nfrom sklearn.metrics import confusion_matrix \\nconfusion_matrix(y_test,y_pred)'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''y_pred = model.predict(x_test) \n",
    "from sklearn.metrics import confusion_matrix \n",
    "confusion_matrix(y_test,y_pred)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baf164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb419a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(y_pred,0) # To roundoff the values of predicted y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc223b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "confusion_matrix(np.array(y_test),y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3db8219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "plt.plot(model.history.history['acc']) \n",
    "plt.plot(model.history.history['val_acc']) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c678a7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a7497e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=customer[['MonthlyCharges','tenure','TotalCharges']]#Features \n",
    "y=customer[['Churn']]#Target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c8ea834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "daefc0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "model.add(Dense(12, input_dim=3, activation='relu')) \n",
    "model.add(Dense(8, activation='relu')) \n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "056d338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e92dac76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 3.8969 - accuracy: 0.6462 - val_loss: 0.5132 - val_accuracy: 0.7354\n",
      "Epoch 2/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.7183 - val_loss: 0.5090 - val_accuracy: 0.7293\n",
      "Epoch 3/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.7134 - val_loss: 0.6911 - val_accuracy: 0.7293\n",
      "Epoch 4/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6113 - accuracy: 0.7221 - val_loss: 0.8033 - val_accuracy: 0.7293\n",
      "Epoch 5/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.6992 - val_loss: 0.4849 - val_accuracy: 0.7757\n",
      "Epoch 6/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6638 - accuracy: 0.7160 - val_loss: 1.5246 - val_accuracy: 0.7307\n",
      "Epoch 7/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.8941 - accuracy: 0.7010 - val_loss: 1.3489 - val_accuracy: 0.7288\n",
      "Epoch 8/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.7280 - val_loss: 1.0517 - val_accuracy: 0.7274\n",
      "Epoch 9/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.7237 - val_loss: 0.4900 - val_accuracy: 0.7534\n",
      "Epoch 10/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.7349 - val_loss: 0.7434 - val_accuracy: 0.6053\n",
      "Epoch 11/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7144 - accuracy: 0.7083 - val_loss: 1.4486 - val_accuracy: 0.7288\n",
      "Epoch 12/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.7282 - val_loss: 0.5679 - val_accuracy: 0.7444\n",
      "Epoch 13/150\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.7340 - accuracy: 0.7146 - val_loss: 0.7393 - val_accuracy: 0.7392\n",
      "Epoch 14/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.7343 - val_loss: 0.6162 - val_accuracy: 0.7175\n",
      "Epoch 15/150\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.7034 - accuracy: 0.7181 - val_loss: 0.4695 - val_accuracy: 0.7752\n",
      "Epoch 16/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7424 - val_loss: 0.4865 - val_accuracy: 0.7539\n",
      "Epoch 17/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.7379 - val_loss: 0.5142 - val_accuracy: 0.7444\n",
      "Epoch 18/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.7367 - val_loss: 0.5449 - val_accuracy: 0.7449\n",
      "Epoch 19/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7473 - val_loss: 0.5921 - val_accuracy: 0.7392\n",
      "Epoch 20/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.7280 - val_loss: 1.0184 - val_accuracy: 0.5078\n",
      "Epoch 21/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7648 - accuracy: 0.7219 - val_loss: 0.4897 - val_accuracy: 0.7643\n",
      "Epoch 22/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.7387 - val_loss: 0.6282 - val_accuracy: 0.6914\n",
      "Epoch 23/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6442 - accuracy: 0.7335 - val_loss: 3.4073 - val_accuracy: 0.3720\n",
      "Epoch 24/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7422 - accuracy: 0.7274 - val_loss: 0.6417 - val_accuracy: 0.7421\n",
      "Epoch 25/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7481 - val_loss: 0.8644 - val_accuracy: 0.7359\n",
      "Epoch 26/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5912 - accuracy: 0.7365 - val_loss: 0.9230 - val_accuracy: 0.7340\n",
      "Epoch 27/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7800 - accuracy: 0.7191 - val_loss: 0.5813 - val_accuracy: 0.7478\n",
      "Epoch 28/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6348 - accuracy: 0.7323 - val_loss: 0.5998 - val_accuracy: 0.7104\n",
      "Epoch 29/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7053 - accuracy: 0.7247 - val_loss: 0.4852 - val_accuracy: 0.7719\n",
      "Epoch 30/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7679 - accuracy: 0.7172 - val_loss: 0.6191 - val_accuracy: 0.7482\n",
      "Epoch 31/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7458 - val_loss: 2.0037 - val_accuracy: 0.4089\n",
      "Epoch 32/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6733 - accuracy: 0.7298 - val_loss: 0.5460 - val_accuracy: 0.7496\n",
      "Epoch 33/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7499 - accuracy: 0.7130 - val_loss: 0.8911 - val_accuracy: 0.7388\n",
      "Epoch 34/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6202 - accuracy: 0.7383 - val_loss: 0.4718 - val_accuracy: 0.7809\n",
      "Epoch 35/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.7398 - val_loss: 0.5915 - val_accuracy: 0.7459\n",
      "Epoch 36/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6554 - accuracy: 0.7284 - val_loss: 0.4640 - val_accuracy: 0.7761\n",
      "Epoch 37/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7342 - accuracy: 0.7266 - val_loss: 0.4734 - val_accuracy: 0.7837\n",
      "Epoch 38/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.7479 - val_loss: 0.4685 - val_accuracy: 0.7705\n",
      "Epoch 39/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7146 - accuracy: 0.7249 - val_loss: 1.5635 - val_accuracy: 0.7345\n",
      "Epoch 40/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7908 - accuracy: 0.7316 - val_loss: 1.3644 - val_accuracy: 0.4799\n",
      "Epoch 41/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.7343 - val_loss: 0.4756 - val_accuracy: 0.7804\n",
      "Epoch 42/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.7359 - val_loss: 0.4636 - val_accuracy: 0.7809\n",
      "Epoch 43/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.7298 - val_loss: 1.4968 - val_accuracy: 0.4510\n",
      "Epoch 44/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.7420 - val_loss: 2.5926 - val_accuracy: 0.3843\n",
      "Epoch 45/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7479 - accuracy: 0.7341 - val_loss: 0.8826 - val_accuracy: 0.7392\n",
      "Epoch 46/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.7298 - val_loss: 0.4976 - val_accuracy: 0.7681\n",
      "Epoch 47/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6414 - accuracy: 0.7434 - val_loss: 0.4750 - val_accuracy: 0.7809\n",
      "Epoch 48/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7552 - val_loss: 0.5242 - val_accuracy: 0.7378\n",
      "Epoch 49/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7024 - accuracy: 0.7219 - val_loss: 0.6280 - val_accuracy: 0.7099\n",
      "Epoch 50/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7261 - accuracy: 0.7256 - val_loss: 0.4734 - val_accuracy: 0.7780\n",
      "Epoch 51/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.7422 - val_loss: 1.4199 - val_accuracy: 0.4742\n",
      "Epoch 52/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.7406 - val_loss: 0.4581 - val_accuracy: 0.7804\n",
      "Epoch 53/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6149 - accuracy: 0.7355 - val_loss: 0.5248 - val_accuracy: 0.7430\n",
      "Epoch 54/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7517 - val_loss: 0.6789 - val_accuracy: 0.7430\n",
      "Epoch 55/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.7448 - val_loss: 0.6359 - val_accuracy: 0.6735\n",
      "Epoch 56/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7186 - accuracy: 0.7302 - val_loss: 0.9512 - val_accuracy: 0.7354\n",
      "Epoch 57/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7204 - accuracy: 0.7339 - val_loss: 0.4648 - val_accuracy: 0.7780\n",
      "Epoch 58/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.7424 - val_loss: 0.4645 - val_accuracy: 0.7875\n",
      "Epoch 59/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.7260 - val_loss: 0.4636 - val_accuracy: 0.7799\n",
      "Epoch 60/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.7310 - val_loss: 0.5027 - val_accuracy: 0.7743\n",
      "Epoch 61/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.7554 - val_loss: 0.5227 - val_accuracy: 0.7378\n",
      "Epoch 62/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7515 - val_loss: 0.4982 - val_accuracy: 0.7582\n",
      "Epoch 63/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.7515 - val_loss: 0.7153 - val_accuracy: 0.6488\n",
      "Epoch 64/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.7308 - val_loss: 0.7429 - val_accuracy: 0.6474\n",
      "Epoch 65/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.7329 - val_loss: 0.7735 - val_accuracy: 0.7421\n",
      "Epoch 66/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.7306 - val_loss: 0.5075 - val_accuracy: 0.7567\n",
      "Epoch 67/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6753 - accuracy: 0.7211 - val_loss: 1.2032 - val_accuracy: 0.7336\n",
      "Epoch 68/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6281 - accuracy: 0.7503 - val_loss: 0.6702 - val_accuracy: 0.6668\n",
      "Epoch 69/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7444 - val_loss: 1.0917 - val_accuracy: 0.5106\n",
      "Epoch 70/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6023 - accuracy: 0.7406 - val_loss: 0.4515 - val_accuracy: 0.7795\n",
      "Epoch 71/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7548 - val_loss: 0.8995 - val_accuracy: 0.7312\n",
      "Epoch 72/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7316 - accuracy: 0.7215 - val_loss: 0.4612 - val_accuracy: 0.7785\n",
      "Epoch 73/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5896 - accuracy: 0.7487 - val_loss: 0.6883 - val_accuracy: 0.6593\n",
      "Epoch 74/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6157 - accuracy: 0.7428 - val_loss: 0.5763 - val_accuracy: 0.7104\n",
      "Epoch 75/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.7327 - val_loss: 0.8876 - val_accuracy: 0.6048\n",
      "Epoch 76/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7460 - val_loss: 0.7493 - val_accuracy: 0.6422\n",
      "Epoch 77/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7485 - val_loss: 0.5543 - val_accuracy: 0.7496\n",
      "Epoch 78/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7422 - val_loss: 0.7641 - val_accuracy: 0.7416\n",
      "Epoch 79/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7513 - val_loss: 1.1896 - val_accuracy: 0.7345\n",
      "Epoch 80/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.7495 - val_loss: 0.4571 - val_accuracy: 0.7738\n",
      "Epoch 81/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.7462 - val_loss: 0.9476 - val_accuracy: 0.7364\n",
      "Epoch 82/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7450 - val_loss: 0.8266 - val_accuracy: 0.7354\n",
      "Epoch 83/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6712 - accuracy: 0.7335 - val_loss: 0.4773 - val_accuracy: 0.7705\n",
      "Epoch 84/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.7517 - val_loss: 0.5263 - val_accuracy: 0.7388\n",
      "Epoch 85/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7572 - val_loss: 0.4933 - val_accuracy: 0.7619\n",
      "Epoch 86/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7467 - val_loss: 1.0163 - val_accuracy: 0.7345\n",
      "Epoch 87/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6420 - accuracy: 0.7365 - val_loss: 1.0425 - val_accuracy: 0.5239\n",
      "Epoch 88/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6065 - accuracy: 0.7513 - val_loss: 2.0504 - val_accuracy: 0.4080\n",
      "Epoch 89/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.7452 - val_loss: 0.7024 - val_accuracy: 0.7411\n",
      "Epoch 90/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.7462 - val_loss: 0.8134 - val_accuracy: 0.7364\n",
      "Epoch 91/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.7471 - val_loss: 0.4703 - val_accuracy: 0.7842\n",
      "Epoch 92/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7548 - val_loss: 0.5108 - val_accuracy: 0.7567\n",
      "Epoch 93/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7495 - val_loss: 2.5957 - val_accuracy: 0.3862\n",
      "Epoch 94/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6438 - accuracy: 0.7391 - val_loss: 2.0092 - val_accuracy: 0.7326\n",
      "Epoch 95/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9489 - accuracy: 0.7280 - val_loss: 2.4349 - val_accuracy: 0.3966\n",
      "Epoch 96/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7192 - accuracy: 0.7288 - val_loss: 0.5393 - val_accuracy: 0.7359\n",
      "Epoch 97/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.7438 - val_loss: 0.6278 - val_accuracy: 0.7435\n",
      "Epoch 98/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6659 - accuracy: 0.7359 - val_loss: 0.7221 - val_accuracy: 0.6597\n",
      "Epoch 99/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.7473 - val_loss: 0.4678 - val_accuracy: 0.7766\n",
      "Epoch 100/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.7507 - val_loss: 0.6817 - val_accuracy: 0.6616\n",
      "Epoch 101/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6437 - accuracy: 0.7343 - val_loss: 0.4655 - val_accuracy: 0.7743\n",
      "Epoch 102/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.7369 - val_loss: 1.5487 - val_accuracy: 0.7331\n",
      "Epoch 103/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6640 - accuracy: 0.7377 - val_loss: 0.4751 - val_accuracy: 0.7861\n",
      "Epoch 104/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7556 - val_loss: 1.2279 - val_accuracy: 0.4766\n",
      "Epoch 105/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.7422 - val_loss: 0.7704 - val_accuracy: 0.6337\n",
      "Epoch 106/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.7426 - val_loss: 0.6902 - val_accuracy: 0.6607\n",
      "Epoch 107/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7576 - val_loss: 0.9521 - val_accuracy: 0.5551\n",
      "Epoch 108/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.7312 - val_loss: 0.5063 - val_accuracy: 0.7662\n",
      "Epoch 109/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.7578 - val_loss: 0.7669 - val_accuracy: 0.6285\n",
      "Epoch 110/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6428 - accuracy: 0.7363 - val_loss: 0.4581 - val_accuracy: 0.7847\n",
      "Epoch 111/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.7600 - val_loss: 0.4872 - val_accuracy: 0.7676\n",
      "Epoch 112/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7564 - val_loss: 1.8213 - val_accuracy: 0.4240\n",
      "Epoch 113/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.7302 - val_loss: 1.2389 - val_accuracy: 0.7340\n",
      "Epoch 114/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.7349 - val_loss: 0.4907 - val_accuracy: 0.7681\n",
      "Epoch 115/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.7454 - val_loss: 0.4749 - val_accuracy: 0.7866\n",
      "Epoch 116/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7513 - val_loss: 0.6013 - val_accuracy: 0.7501\n",
      "Epoch 117/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7511 - val_loss: 0.8917 - val_accuracy: 0.7345\n",
      "Epoch 118/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.7381 - val_loss: 0.9289 - val_accuracy: 0.5906\n",
      "Epoch 119/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6211 - accuracy: 0.7420 - val_loss: 0.4544 - val_accuracy: 0.7733\n",
      "Epoch 120/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.7414 - val_loss: 0.4646 - val_accuracy: 0.7828\n",
      "Epoch 121/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.7410 - val_loss: 0.5685 - val_accuracy: 0.7227\n",
      "Epoch 122/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7588 - val_loss: 1.0631 - val_accuracy: 0.5168\n",
      "Epoch 123/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.7448 - val_loss: 0.7711 - val_accuracy: 0.6403\n",
      "Epoch 124/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7509 - val_loss: 0.7573 - val_accuracy: 0.6356\n",
      "Epoch 125/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7503 - val_loss: 0.5452 - val_accuracy: 0.7246\n",
      "Epoch 126/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.7408 - val_loss: 2.5911 - val_accuracy: 0.3852\n",
      "Epoch 127/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6744 - accuracy: 0.7375 - val_loss: 0.4505 - val_accuracy: 0.7747\n",
      "Epoch 128/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7580 - val_loss: 1.3230 - val_accuracy: 0.7336\n",
      "Epoch 129/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6384 - accuracy: 0.7519 - val_loss: 0.8280 - val_accuracy: 0.6152\n",
      "Epoch 130/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.7373 - val_loss: 0.4563 - val_accuracy: 0.7776\n",
      "Epoch 131/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7548 - val_loss: 1.0232 - val_accuracy: 0.5438\n",
      "Epoch 132/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.7353 - val_loss: 1.3225 - val_accuracy: 0.4780\n",
      "Epoch 133/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6216 - accuracy: 0.7418 - val_loss: 0.4832 - val_accuracy: 0.7776\n",
      "Epoch 134/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6219 - accuracy: 0.7387 - val_loss: 0.4854 - val_accuracy: 0.7738\n",
      "Epoch 135/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7458 - val_loss: 0.4824 - val_accuracy: 0.7780\n",
      "Epoch 136/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7529 - val_loss: 0.4530 - val_accuracy: 0.7733\n",
      "Epoch 137/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7497 - val_loss: 0.4770 - val_accuracy: 0.7657\n",
      "Epoch 138/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7430 - val_loss: 1.6970 - val_accuracy: 0.7336\n",
      "Epoch 139/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.7351 - val_loss: 0.4805 - val_accuracy: 0.7832\n",
      "Epoch 140/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7503 - val_loss: 0.5030 - val_accuracy: 0.7601\n",
      "Epoch 141/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6139 - accuracy: 0.7473 - val_loss: 1.2669 - val_accuracy: 0.4875\n",
      "Epoch 142/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7103 - accuracy: 0.7316 - val_loss: 0.9149 - val_accuracy: 0.7340\n",
      "Epoch 143/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7264 - accuracy: 0.7335 - val_loss: 0.4575 - val_accuracy: 0.7832\n",
      "Epoch 144/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7560 - val_loss: 0.5834 - val_accuracy: 0.7397\n",
      "Epoch 145/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7509 - val_loss: 0.5852 - val_accuracy: 0.7459\n",
      "Epoch 146/150\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6673 - accuracy: 0.7389 - val_loss: 0.8078 - val_accuracy: 0.6086\n",
      "Epoch 147/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7546 - val_loss: 0.6233 - val_accuracy: 0.7388\n",
      "Epoch 148/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.7306 - val_loss: 0.4867 - val_accuracy: 0.7861\n",
      "Epoch 149/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6524 - accuracy: 0.7367 - val_loss: 1.3602 - val_accuracy: 0.4690\n",
      "Epoch 150/150\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.7448 - val_loss: 0.4548 - val_accuracy: 0.7757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1aa1ff1d3d0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=150,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b7ee8c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "93d08f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5522</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6377</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5500</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2113 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Churn\n",
       "185       1\n",
       "2715      0\n",
       "3825      0\n",
       "1807      1\n",
       "132       0\n",
       "...     ...\n",
       "5522      1\n",
       "6377      1\n",
       "5500      0\n",
       "2392      0\n",
       "6705      0\n",
       "\n",
       "[2113 rows x 1 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9119131e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3212119 ],\n",
       "       [0.00598452],\n",
       "       [0.02609227],\n",
       "       ...,\n",
       "       [0.01402795],\n",
       "       [0.457597  ],\n",
       "       [0.1346977 ]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "plt.plot(model.history.history['acc']) \n",
    "plt.plot(model.history.history['val_acc']) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "41350e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(y_pred,0) # To roundoff the values of predicted y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b49b99cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1386,  153],\n",
       "       [ 320,  254]], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "confusion_matrix(np.array(y_test),y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca8e49c",
   "metadata": {},
   "source": [
    "Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c387051",
   "metadata": {},
   "outputs": [],
   "source": [
    "The first model gave us a mean validation accuracy of 75.62%, the second model had accuracy \n",
    "of 73.42 and the third model had a mean validation accuracy of 74.24%. \n",
    "The second model gave us the least accuracy because we added two dropout layers with high \n",
    "probabilities of dropout. \n",
    "Now, there could be many factors why third model’s accuracy was less than that of first model. \n",
    "Most probably one or more of the features used during the model building could be of less \n",
    "significance leading to the reduction in accuracy. \n",
    "It should also be kept in mind that these accuracy values are very specific to the \n",
    "hyperparameters used during the model building process such as optimizers, activation \n",
    "functions and number of epochs. If we were to tweak these hyperparameters we would get \n",
    "completely different accuracy values for all the three models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
